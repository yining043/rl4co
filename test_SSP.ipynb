{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f4d4c0-44f8-4885-a6cd-f6e0432920cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "import torch\n",
    "from torch import nn\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, RichModelSummary\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b257be7c-4afc-4b81-835a-b3c141937c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl4co.envs import SSPEnv\n",
    "from rl4co.models.zoo.am import AttentionModelPolicy, AttentionModel\n",
    "from rl4co.utils.trainer import RL4COTrainer\n",
    "from rl4co.utils.decoding import random_policy, rollout\n",
    "from rl4co.utils.ops import gather_by_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0e76b1-53a3-4b2e-8979-72cfa16b7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSPInitEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, fixed_len, linear_bias=True):\n",
    "        super(SSPInitEmbedding, self).__init__()\n",
    "        node_dim = fixed_len  # x, y\n",
    "        self.init_embed = nn.Linear(node_dim, embedding_dim, linear_bias)\n",
    "\n",
    "    def forward(self, td):\n",
    "        out = self.init_embed(td[\"codes\"])\n",
    "        return out\n",
    "\n",
    "class SSPContext(nn.Module):\n",
    "    \"\"\"Context embedding for the Traveling Salesman Problem (TSP).\n",
    "    Project the following to the embedding space:\n",
    "        - first node embedding\n",
    "        - current node embedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim,  linear_bias=True):\n",
    "        super(SSPContext, self).__init__()\n",
    "        self.W_placeholder = nn.Parameter(\n",
    "            torch.Tensor(embedding_dim).uniform_(-1, 1)\n",
    "        )\n",
    "        self.project_context = nn.Linear(\n",
    "            embedding_dim, embedding_dim, bias=linear_bias\n",
    "        )\n",
    "\n",
    "    def forward(self, embeddings, td):\n",
    "        batch_size = embeddings.size(0)\n",
    "        # By default, node_dim = -1 (we only have one node embedding per node)\n",
    "        node_dim = (\n",
    "            (-1,) if td[\"current_node\"].dim() == 1 else (td[\"current_node\"].size(-1), -1)\n",
    "        )\n",
    "        if td[\"i\"][(0,) * td[\"i\"].dim()].item() < 1:  # get first item fast\n",
    "            context_embedding = self.W_placeholder[None, :].expand(\n",
    "                batch_size, self.W_placeholder.size(-1)\n",
    "            )\n",
    "        else:\n",
    "            context_embedding = gather_by_index(\n",
    "                embeddings,\n",
    "                torch.stack([td[\"current_node\"]], -1).view(\n",
    "                    batch_size, -1\n",
    "                ),\n",
    "            ).view(batch_size, *node_dim)\n",
    "        return self.project_context(context_embedding)\n",
    "        \n",
    "class StaticEmbedding(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(StaticEmbedding, self).__init__()\n",
    "\n",
    "    def forward(self, td):\n",
    "        return 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b06951-f8dd-47d9-94c6-e5f563d159ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n",
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/core/saving.py:188: Found keys that are not in the model state dict but in the checkpoint: ['baseline.baseline.policy.encoder.init_embedding.init_embed.weight', 'baseline.baseline.policy.encoder.init_embedding.init_embed.bias', 'baseline.baseline.policy.encoder.net.layers.0.0.module.Wqkv.weight', 'baseline.baseline.policy.encoder.net.layers.0.0.module.Wqkv.bias', 'baseline.baseline.policy.encoder.net.layers.0.0.module.out_proj.weight', 'baseline.baseline.policy.encoder.net.layers.0.0.module.out_proj.bias', 'baseline.baseline.policy.encoder.net.layers.0.1.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.0.1.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.0.2.module.0.weight', 'baseline.baseline.policy.encoder.net.layers.0.2.module.0.bias', 'baseline.baseline.policy.encoder.net.layers.0.2.module.2.weight', 'baseline.baseline.policy.encoder.net.layers.0.2.module.2.bias', 'baseline.baseline.policy.encoder.net.layers.0.3.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.0.3.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.1.0.module.Wqkv.weight', 'baseline.baseline.policy.encoder.net.layers.1.0.module.Wqkv.bias', 'baseline.baseline.policy.encoder.net.layers.1.0.module.out_proj.weight', 'baseline.baseline.policy.encoder.net.layers.1.0.module.out_proj.bias', 'baseline.baseline.policy.encoder.net.layers.1.1.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.1.1.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.1.2.module.0.weight', 'baseline.baseline.policy.encoder.net.layers.1.2.module.0.bias', 'baseline.baseline.policy.encoder.net.layers.1.2.module.2.weight', 'baseline.baseline.policy.encoder.net.layers.1.2.module.2.bias', 'baseline.baseline.policy.encoder.net.layers.1.3.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.1.3.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.2.0.module.Wqkv.weight', 'baseline.baseline.policy.encoder.net.layers.2.0.module.Wqkv.bias', 'baseline.baseline.policy.encoder.net.layers.2.0.module.out_proj.weight', 'baseline.baseline.policy.encoder.net.layers.2.0.module.out_proj.bias', 'baseline.baseline.policy.encoder.net.layers.2.1.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.2.1.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.2.2.module.0.weight', 'baseline.baseline.policy.encoder.net.layers.2.2.module.0.bias', 'baseline.baseline.policy.encoder.net.layers.2.2.module.2.weight', 'baseline.baseline.policy.encoder.net.layers.2.2.module.2.bias', 'baseline.baseline.policy.encoder.net.layers.2.3.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.2.3.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.3.0.module.Wqkv.weight', 'baseline.baseline.policy.encoder.net.layers.3.0.module.Wqkv.bias', 'baseline.baseline.policy.encoder.net.layers.3.0.module.out_proj.weight', 'baseline.baseline.policy.encoder.net.layers.3.0.module.out_proj.bias', 'baseline.baseline.policy.encoder.net.layers.3.1.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.3.1.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.3.2.module.0.weight', 'baseline.baseline.policy.encoder.net.layers.3.2.module.0.bias', 'baseline.baseline.policy.encoder.net.layers.3.2.module.2.weight', 'baseline.baseline.policy.encoder.net.layers.3.2.module.2.bias', 'baseline.baseline.policy.encoder.net.layers.3.3.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.3.3.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.4.0.module.Wqkv.weight', 'baseline.baseline.policy.encoder.net.layers.4.0.module.Wqkv.bias', 'baseline.baseline.policy.encoder.net.layers.4.0.module.out_proj.weight', 'baseline.baseline.policy.encoder.net.layers.4.0.module.out_proj.bias', 'baseline.baseline.policy.encoder.net.layers.4.1.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.4.1.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.4.2.module.0.weight', 'baseline.baseline.policy.encoder.net.layers.4.2.module.0.bias', 'baseline.baseline.policy.encoder.net.layers.4.2.module.2.weight', 'baseline.baseline.policy.encoder.net.layers.4.2.module.2.bias', 'baseline.baseline.policy.encoder.net.layers.4.3.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.4.3.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.5.0.module.Wqkv.weight', 'baseline.baseline.policy.encoder.net.layers.5.0.module.Wqkv.bias', 'baseline.baseline.policy.encoder.net.layers.5.0.module.out_proj.weight', 'baseline.baseline.policy.encoder.net.layers.5.0.module.out_proj.bias', 'baseline.baseline.policy.encoder.net.layers.5.1.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.5.1.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.5.2.module.0.weight', 'baseline.baseline.policy.encoder.net.layers.5.2.module.0.bias', 'baseline.baseline.policy.encoder.net.layers.5.2.module.2.weight', 'baseline.baseline.policy.encoder.net.layers.5.2.module.2.bias', 'baseline.baseline.policy.encoder.net.layers.5.3.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.5.3.normalizer.bias', 'baseline.baseline.policy.decoder.context_embedding.W_placeholder', 'baseline.baseline.policy.decoder.context_embedding.project_context.weight', 'baseline.baseline.policy.decoder.context_embedding.project_context.bias', 'baseline.baseline.policy.decoder.pointer.project_out.weight', 'baseline.baseline.policy.decoder.project_node_embeddings.weight', 'baseline.baseline.policy.decoder.project_fixed_context.weight']\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-06-04 13:54:46.748024: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-04 13:54:46.781936: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 13:54:47.617989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "val_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=27` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f9e83fe6374094843a3e7ca22b7144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/reward        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -10.14749526977539     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/reward       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -10.14749526977539    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_loc = 100\n",
    "fixed_len = 15\n",
    "emb_dim = 128\n",
    "\n",
    "env = SSPEnv(generator_params={\"num_loc\":num_loc,\n",
    "                              \"fixed_len\":fixed_len},\n",
    "            test_file = \"ssp_100_15.npz\")\n",
    "\n",
    "checkpoint_path = \"/home/yining/ssp/rl4co/checkpoints_ssp/epoch_epoch=531.ckpt\"\n",
    "\n",
    "# Model: default is AM with REINFORCE and greedy rollout baseline\n",
    "model = AttentionModel.load_from_checkpoint(checkpoint_path)\n",
    "model.env = env\n",
    "model.data_cfg[\"test_batch_size\"] = 10000\n",
    "model.data_cfg[\"test_data_size\"] = 10000\n",
    "\n",
    "from rl4co.utils.trainer import RL4COTrainer\n",
    "\n",
    "# We use our own wrapper around Lightning's `Trainer` to make it easier to use\n",
    "trainer = RL4COTrainer(max_epochs=1000, \n",
    "                       accelerator = 'gpu', \n",
    "                       devices=1,   \n",
    "                       # logger=logger,\n",
    "                       # callbacks=callbacks,\n",
    "                      )\n",
    "\n",
    "out = trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e581f2c-768d-4126-86c7-b30db041ee53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL constructive length:\t 1014.75,\tgap: 0.00%,\t time: 1s \t(GPU in parallel)\n",
      "------------------------------------------------------------------------------------------\n",
      "15-mers-greedy length:\t 1483.70,\tgap: 46.21%,\t time: 38s \t(CPU in series)\n",
      "14-mers-greedy length:\t 1444.29,\tgap: 42.33%,\t time: 1m36s \t(CPU in series)\n",
      "10-mers-greedy length:\t 1264.77,\tgap: 24.64%,\t time: 6m10s \t(CPU in series)\n",
      "5-mers-greedy length:\t 977.88,\tgap: -3.63%,\t time: 20m59s \t(CPU in series)\n",
      "3-mers-greedy length:\t 940.53,\tgap: -7.31%,\t time: 43m02s \t(CPU in series)\n",
      "2-mers-greedy length:\t 920.37,\tgap: -9.30%,\t time: 1h8m \t(CPU in series)\n",
      "1-mers-greedy length:\t 905.13,\tgap: -10.80%,\t time: 1h50m \t(CPU in series)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "ks = [1, 2, 3, 5, 10, 14, 15][::-1]\n",
    "time = ['1h50m', '1h8m','43m02s','20m59s', '6m10s', '1m36s', '38s'][::-1]\n",
    "RL = out[0][\"test/reward\"] * env.generator.num_loc * -1\n",
    "print(f\"RL constructive length:\\t {RL:.2f},\\tgap: {0:.2f}%,\\t time: 1s \\t(GPU in parallel)\")\n",
    "print('-' * 90)\n",
    "\n",
    "for k, t in zip(ks, time):\n",
    "    greedy_baseline = np.load(f'greedy_{k}-mers_output.npz')[\"arr_0\"].mean()\n",
    "    gap = (greedy_baseline - RL) / RL * 100\n",
    "    print(f\"{k}-mers-greedy length:\\t {greedy_baseline:.2f},\\tgap: {gap:.2f}%,\\t time: {t} \\t(CPU in series)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4603bc1e-afff-4d73-8ffb-ac1ab5b2092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict.tensordict import TensorDict\n",
    "from tqdm import tqdm\n",
    "td = TensorDict({\"codes\": torch.tensor(np.load(\"data/ssp_100_15.npz\")[\"codes\"])}, batch_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3514fb43-de23-44f4-b35a-4a6ec401d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▎                                                            | 100/400 [05:55<18:27,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling: 100 length: 988.6712074279785 gap: -2.569926751011708 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▌                                        | 200/400 [12:02<12:11,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling: 200 length: 985.7806205749512 gap: -2.854783927702102 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████▊                    | 300/400 [18:07<06:05,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling: 300 length: 984.1910362243652 gap: -3.0114318795686636 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 400/400 [24:12<00:00,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling: 400 length: 983.0849647521973 gap: -3.1204313363570235 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Sampling rollouts over trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "td_init = model.env.reset(td).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "rewards_best = None\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(400)):\n",
    "        out = model(td_init.clone(), phase=\"test\", decode_type=\"sampling\", return_actions=False)\n",
    "        rewards_now = out['reward'].cpu().detach()\n",
    "        if rewards_best is None:\n",
    "            rewards_best = rewards_now\n",
    "        else:\n",
    "            rewards_best = torch.max(rewards_now, rewards_best)\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            obj = -rewards_best.mean().numpy() * env.generator.num_loc\n",
    "            print('Sampling:', i+1, 'length:', obj,  'gap:', (obj - RL) / RL * 100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
