{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ef501c-6089-430f-a836-604f0f2edab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "import torch\n",
    "from torch import nn\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, RichModelSummary\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bfc02c5-7fb4-45d7-94c9-b6d8eb813fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl4co.envs import SSPEnv\n",
    "from rl4co.models.zoo.am import AttentionModelPolicy, AttentionModel\n",
    "from rl4co.utils.trainer import RL4COTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e0225b-75d2-4592-b6cd-1ec84e181682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSP codes:\n",
      " tensor([[0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.]]) \n",
      "\n",
      " Suggested order: tensor([2, 3, 7, 8, 5, 0, 6, 1, 4, 9]) \n",
      "\n",
      " Sorted codes according to the order:\n",
      " tensor([[1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1.],\n",
      "        [1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0.]])\n",
      "\n",
      "Constructed Superstring: 1110101010011010011111101100010011110010000000111111000001010000000111111010010110001111010100001111111111010110000011000100101110010\n",
      "Superstring Length: 133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-13.3000, -13.5000, -14.5000]), None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rl4co.utils.decoding import random_policy, rollout\n",
    "from rl4co.utils.ops import gather_by_index\n",
    "\n",
    "# RL4CO env based on TorchRL\n",
    "env = SSPEnv(generator_params=dict(num_loc=10, fixed_len=15))\n",
    "td = env.reset(batch_size=[3])\n",
    "# env.render(td)\n",
    "\n",
    "reward, td, actions = rollout(env, env.reset(batch_size=[3]), random_policy)\n",
    "reward, env.render(td, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ae1029-a5de-4442-be87-97e355e29da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSPInitEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, fixed_len, linear_bias=True):\n",
    "        super(SSPInitEmbedding, self).__init__()\n",
    "        node_dim = fixed_len  # x, y\n",
    "        self.init_embed = nn.Linear(node_dim, embedding_dim, linear_bias)\n",
    "\n",
    "    def forward(self, td):\n",
    "        out = self.init_embed(td[\"codes\"])\n",
    "        return out\n",
    "\n",
    "class SSPContext(nn.Module):\n",
    "    \"\"\"Context embedding for the Traveling Salesman Problem (TSP).\n",
    "    Project the following to the embedding space:\n",
    "        - first node embedding\n",
    "        - current node embedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim,  linear_bias=True):\n",
    "        super(SSPContext, self).__init__()\n",
    "        self.W_placeholder = nn.Parameter(\n",
    "            torch.Tensor(embedding_dim).uniform_(-1, 1)\n",
    "        )\n",
    "        self.project_context = nn.Linear(\n",
    "            embedding_dim, embedding_dim, bias=linear_bias\n",
    "        )\n",
    "\n",
    "    def forward(self, embeddings, td):\n",
    "        batch_size = embeddings.size(0)\n",
    "        # By default, node_dim = -1 (we only have one node embedding per node)\n",
    "        node_dim = (\n",
    "            (-1,) if td[\"current_node\"].dim() == 1 else (td[\"current_node\"].size(-1), -1)\n",
    "        )\n",
    "        if td[\"i\"][(0,) * td[\"i\"].dim()].item() < 1:  # get first item fast\n",
    "            context_embedding = self.W_placeholder[None, :].expand(\n",
    "                batch_size, self.W_placeholder.size(-1)\n",
    "            )\n",
    "        else:\n",
    "            context_embedding = gather_by_index(\n",
    "                embeddings,\n",
    "                torch.stack([td[\"current_node\"]], -1).view(\n",
    "                    batch_size, -1\n",
    "                ),\n",
    "            ).view(batch_size, *node_dim)\n",
    "        return self.project_context(context_embedding)\n",
    "        \n",
    "class StaticEmbedding(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(StaticEmbedding, self).__init__()\n",
    "\n",
    "    def forward(self, td):\n",
    "        return 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ba932d-a2c3-4625-881c-84b6a58c02d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "source": [
    "num_loc = 100\n",
    "fixed_len = 15\n",
    "emb_dim = 128\n",
    "\n",
    "env = SSPEnv(generator_params={\"num_loc\":num_loc,\n",
    "                              \"fixed_len\":fixed_len})\n",
    "\n",
    "policy = AttentionModelPolicy(env_name = env.name,\n",
    "                              embed_dim=emb_dim,\n",
    "                              num_encoder_layers=6,\n",
    "                              num_heads=8,\n",
    "                              normalization=\"instance\",\n",
    "                              init_embedding=SSPInitEmbedding(emb_dim, fixed_len),\n",
    "                              context_embedding=SSPContext(emb_dim),\n",
    "                              dynamic_embedding=StaticEmbedding(emb_dim),\n",
    "                              use_graph_context=False\n",
    "                             )\n",
    "\n",
    "# Model: default is AM with REINFORCE and greedy rollout baseline\n",
    "model = AttentionModel(env, \n",
    "            policy=policy,\n",
    "            batch_size=512,\n",
    "            train_data_size=100000,  # each epoch,\n",
    "            val_batch_size=1000,\n",
    "            val_data_size=1000,\n",
    "            test_batch_size=1000,\n",
    "            test_data_size=1000,\n",
    "            optimizer=\"Adam\",\n",
    "            optimizer_kwargs={\"lr\": 1e-4, \"weight_decay\": 1e-6},\n",
    "            lr_scheduler=\"MultiStepLR\",\n",
    "            lr_scheduler_kwargs={\"milestones\": [901, ], \"gamma\": 0.1},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a88118-4fdf-4c7d-9ec7-eb4589fc3880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-06-03 20:53:56.227090: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-03 20:53:56.263796: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-03 20:53:57.116118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=27` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3416d3261589427c8eb0515fd140cbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/reward        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -13.721000671386719    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/reward       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -13.721000671386719   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:653: Checkpoint directory /home/yining/ssp/rl4co/checkpoints_ssp exists and is not empty.\n",
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                                   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>│ env                                    │ SSPEnv                │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>│ policy                                 │ AttentionModelPolicy  │  1.3 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>│ policy.encoder                         │ AttentionModelEncoder │  1.2 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>│ policy.encoder.init_embedding          │ SSPInitEmbedding      │  2.0 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>│ policy.encoder.net                     │ GraphAttentionNetwork │  1.2 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>│ policy.decoder                         │ AttentionModelDecoder │ 98.6 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>│ policy.decoder.context_embedding       │ SSPContext            │ 16.6 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>│ policy.decoder.dynamic_embedding       │ StaticEmbedding       │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>│ policy.decoder.pointer                 │ PointerAttention      │ 16.4 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>│ policy.decoder.project_node_embeddings │ Linear                │ 49.2 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>│ policy.decoder.project_fixed_context   │ Linear                │ 16.4 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>│ baseline                               │ WarmupBaseline        │  1.3 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>│ baseline.baseline                      │ RolloutBaseline       │  1.3 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>│ baseline.baseline.policy               │ AttentionModelPolicy  │  1.3 M │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span>│ baseline.warmup_baseline               │ ExponentialBaseline   │      0 │\n",
       "└────┴────────────────────────────────────────┴───────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0m│ env                                    │ SSPEnv                │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0m│ policy                                 │ AttentionModelPolicy  │  1.3 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder                         │ AttentionModelEncoder │  1.2 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder.init_embedding          │ SSPInitEmbedding      │  2.0 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0m│ policy.encoder.net                     │ GraphAttentionNetwork │  1.2 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder                         │ AttentionModelDecoder │ 98.6 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder.context_embedding       │ SSPContext            │ 16.6 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder.dynamic_embedding       │ StaticEmbedding       │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder.pointer                 │ PointerAttention      │ 16.4 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0m│ policy.decoder.project_node_embeddings │ Linear                │ 49.2 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0m│ policy.decoder.project_fixed_context   │ Linear                │ 16.4 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0m│ baseline                               │ WarmupBaseline        │  1.3 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0m│ baseline.baseline                      │ RolloutBaseline       │  1.3 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0m│ baseline.baseline.policy               │ AttentionModelPolicy  │  1.3 M │\n",
       "│\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0m│ baseline.warmup_baseline               │ ExponentialBaseline   │      0 │\n",
       "└────┴────────────────────────────────────────┴───────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 2.6 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 2.6 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 10                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 2.6 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 2.6 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 10                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=27` in the `DataLoader` to improve performance.\n",
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=27` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac57ad13f5447dd8f539ca1b5fec3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                       | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                     | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                     | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                     | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                     | 0/? [00:00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yining/miniconda3/envs/ai4co/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "# Checkpointing callback: save models when validation reward improves\n",
    "checkpoint_callback = ModelCheckpoint(dirpath=\"checkpoints_ssp\", # save to checkpoints/\n",
    "                                    filename=\"epoch_{epoch:03d}\",  # save as epoch_XXX.ckpt\n",
    "                                    save_top_k=5, # save only the best model\n",
    "                                    save_last=True, # save the last model\n",
    "                                    monitor=\"val/reward\", # monitor validation reward\n",
    "                                    mode=\"max\") # maximize validation reward\n",
    "\n",
    "rich_model_summary = RichModelSummary(max_depth=3)  # model summary callback\n",
    "callbacks = [checkpoint_callback, rich_model_summary]\n",
    "\n",
    "# Logger\n",
    "# logger = WandbLogger(project=\"rl4co\", name=f\"{env.name}_{num_loc}\")\n",
    "logger = None # uncomment this line if you don't want logging\n",
    "\n",
    "\n",
    "\n",
    "# We use our own wrapper around Lightning's `Trainer` to make it easier to use\n",
    "trainer = RL4COTrainer(max_epochs=1000, \n",
    "                       accelerator = 'gpu', \n",
    "                       devices=1,   \n",
    "                       # logger=logger,\n",
    "                       callbacks=callbacks,\n",
    "                      )\n",
    "\n",
    "trainer.test(model)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "63ac6991-b390-4eb0-9683-becbf4b70be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def generate_batch_superstring_data(batch_size, num_str, str_dim, alphabet_size=2):\n",
    "    # Generate random strings\n",
    "    batch_data = torch.randint(0, alphabet_size, (batch_size, num_str, str_dim))\n",
    "    \n",
    "    # Generate random overlap masks\n",
    "    overlap_mask = torch.rand(batch_size, num_str - 1) > 0.5\n",
    "    overlap_lengths = torch.randint(1, str_dim // 2 + 1, (batch_size, num_str - 1))\n",
    "    \n",
    "    # Generate index tensors for efficient slicing\n",
    "    overlap_indices = torch.arange(str_dim).expand(batch_size, num_str - 1, str_dim)\n",
    "    overlap_mask_expanded = overlap_mask.unsqueeze(-1).expand(batch_size, num_str - 1, str_dim)\n",
    "    overlap_lengths_expanded = overlap_lengths.unsqueeze(-1).expand(batch_size, num_str - 1, str_dim)\n",
    "\n",
    "    # Generate a mask for the overlap regions\n",
    "    overlap_region_mask = (overlap_indices < overlap_lengths_expanded) & overlap_mask_expanded\n",
    "    \n",
    "    # Copy the values to the overlap region\n",
    "    previous_strings = batch_data[:, :-1, :].clone()\n",
    "    for i in range(str_dim):\n",
    "        current_mask = overlap_region_mask[:, :, i]\n",
    "        selected_overlap_index_at_i = (str_dim - overlap_lengths + i).view(-1,1) % str_dim\n",
    "        selected_overlap = previous_strings.view(-1, str_dim).gather(1, selected_overlap_index_at_i).view(batch_size, num_str - 1)\n",
    "        batch_data[:, 1:, i][current_mask] = selected_overlap[current_mask]\n",
    "    \n",
    "    # Shuffle the num_str dimension\n",
    "    print(batch_data)\n",
    "    perm = torch.rand(batch_size, num_str).argsort(dim=1)\n",
    "    print(perm)\n",
    "    batch_data = batch_data[torch.arange(batch_size).unsqueeze(1), perm]\n",
    "    \n",
    "    return batch_data.float()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
